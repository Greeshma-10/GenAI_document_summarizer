# GenAI Hierarchical Document Summarization Platform

> A multi-layer GenAI pipeline for summarizing long-form documents in a structured, reliable, and measurable manner.

---

## ğŸ“‹ Overview

Traditional summarization systems often flatten information, omit important sections, or generate ungrounded abstractions. This platform addresses those limitations through:

- **Hierarchical abstraction**
- **Semantic clustering**
- **Evaluation-driven governance mechanisms**

The system is engineered with modular architecture, centralized configuration, structured logging, and prompt isolation to support maintainability and controlled experimentation.

---

## ğŸ§© Core Challenge

Long documents distribute meaning across sections and abstraction levels. Key insights may appear:

- Non-linearly across multiple segments
- At varying conceptual depths
- Inside structured formats such as tables

Naive summarization approaches typically collapse structure and fail to guarantee representation completeness.

### Objectives

- Preserve document hierarchy
- Enable multi-level abstraction
- Quantify representation completeness
- Reduce hallucination risk

---

## ğŸš€ Solution Strategy

The platform follows a hierarchical summarization design:

1. Segment the document into token-aware chunks
2. Generate grounded chunk summaries
3. Reconstruct semantic structure using embeddings
4. Produce section-level abstractions
5. Generate a mode-aware executive synthesis
6. Validate structural and semantic completeness

Each stage introduces controlled abstraction while maintaining traceability to source content.

---

## ğŸ—ï¸ System Architecture

The pipeline is organized into clearly separated layers.

### Interface Layer
- User uploads document (PDF or text)
- Frontend validates request and initiates pipeline

### Layer 1 â€” Ingestion & Preprocessing
- Token-aware chunk generation
- Detection of tabular structures
- Metadata assignment for traceability

### Layer 2 â€” Chunk Abstraction
- Mode-aware filtering (Research vs Academic)
- Numeric preservation logic
- Phrase and keyword grounding checks
- Parallel chunk processing for scalability

### Layer 3 â€” Semantic Section Reconstruction
- Embedding generation (Titan embeddings)
- Agglomerative clustering using cosine distance
- Adaptive threshold tuning to prevent cluster collapse
- Filtering of weak semantic segments

### Layer 4 â€” Section Abstraction
- Deduplication of cross-chunk themes
- Consolidation of related insights
- Handling of sparse or low-density sections
- Preservation of comparative and tabular insights

### Layer 5 â€” Executive Synthesis
- Section importance ranking
- Prioritized synthesis of dominant themes
- Dual-mode prompting:
  - **Research mode** â€” strategic abstraction
  - **Academic mode** â€” explanatory abstraction
- Strict fabrication prevention constraints

### Layer 6 â€” Evaluation & Governance

| Engine | Description |
|---|---|
| **Structural Coverage Engine** | Measures how many meaningful chunks are represented in higher abstractions |
| **Semantic Alignment Engine** | Computes embedding similarity between section summaries and executive output to quantify meaning retention |
| **Reliability Flags** | Detects missing sections, validates coverage thresholds, and flags semantic emptiness |

### Output Layer

Structured JSON response including:

```json
{
  "executive_summary": "...",
  "key_points": ["..."],
  "risks_or_limitations": ["..."],
  "tldr": "...",
  "coverage_metrics": {},
  "reliability_flags": {}
}


https://github.com/user-attachments/assets/06c198f1-fb50-4cf7-8785-92bb5cfb21ed
```

---

## âš™ï¸ Key Engineering Principles

### 1. Configuration-Driven Design
All runtime parameters are centralized in `config.py`, enabling safe experimentation without modifying business logic.

### 2. Prompt Isolation
Prompts are separated by stage to prevent tight coupling between orchestration and LLM policy:

```
prompts/
â”œâ”€â”€ chunk.py
â”œâ”€â”€ section.py
â””â”€â”€ executive.py
```

### 3. Centralized Model Invocation
All Bedrock calls are routed through a single service layer, ensuring retry management, latency control, consistent parsing, and observability.

### 4. Structured Logging
The logging layer tracks model retries, groundedness failures, embedding issues, cluster adjustments, and executive generation failures. Logs are persisted in `logs/app.log`.

### 5. Measurable Completeness
Unlike most summarization systems, this platform introduces quantitative signals:

| Metric | Description |
|---|---|
| **Structural Coverage Score** | Chunk representation completeness |
| **Meaning Coverage Score** | Embedding similarity across abstraction levels |
| **Reliability Flags** | Structural and semantic validation signals |

---

## ğŸ“ Repository Structure

```
â”œâ”€â”€ app/
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ chunk.py
â”‚   â”œâ”€â”€ section.py
â”‚   â””â”€â”€ executive.py
â”œâ”€â”€ services/
â”œâ”€â”€ schema/
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ app.log
â”œâ”€â”€ config.py
â”œâ”€â”€ logger.py
â””â”€â”€ frontend.py
```

---

## ğŸ› ï¸ Technology Stack

| Component | Technology |
|---|---|
| Language | Python |
| Cloud AI | AWS Bedrock |
| LLM | LLaMA 3 |
| Embeddings | Titan Embeddings |
| Clustering | Scikit-learn |
| Numerics | NumPy |
| Frontend | Streamlit |

---

## ğŸ“ˆ Performance Characteristics

- Parallel chunk processing
- Stage-level latency measurement
- End-to-end runtime tracking

Empirical tests across increasing token sizes demonstrate **stable structural coverage** and **strong semantic alignment** across abstraction levels.

---

## ğŸ”® Future Enhancements

- [ ] Retrieval-augmented grounding verification
- [ ] Multimodal document support
- [ ] Model benchmarking framework
- [ ] Token usage telemetry
- [ ] Containerized deployment

---

## ğŸ“ Summary

This project demonstrates how long-form document summarization can be approached as a **structured, hierarchical, and evaluable system** rather than a single-pass generation task. It integrates abstraction control, semantic reconstruction, grounding validation, and measurable completeness into a cohesive GenAI architecture.
